{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курс \"Введение в анализ данных\", весна 2018\n",
    "## Семинар 3. Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этом семинаре мы: \n",
    "- познакомимся с популярной библиотекой для машинного обучения [scikit-learn](http://scikit-learn.org/stable/);\n",
    "- поговорим про оценку качества алгоритмов и кросс-валидацию;\n",
    "- решим несколько простых задач машинного обучения с помощью scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn — это библиотека...:\n",
    "- с большинством популярных и не очень алгоритмов машинного обучения с __единым интерфейсом работы__;\n",
    "- с большинством необходимым для машинного обучения вспомогательных утилит (преобразование признаков, метрики для оценки качества, ...);\n",
    "- с подробной документацией и множеством примеров решения задач.\n",
    "\n",
    "Можно сказать, что почти любой алгоритм, с которым вы столкнётесь (если это не связано со свежей статьёй или нейросетями), уже реализован в scikit-learn. Не бойтесь лезть в поисковик или [документацию](http://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Начнём.__\n",
    "\n",
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на разделы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import <press tab>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- datasets — \"игрушечные датасеты\", функции для генерации или загрузки выборок\n",
    "- feature_extraction — функции для извлечения признаков\n",
    "- linear_model — линейный модели машинного обучения\n",
    "- metrics — метрики для оценки качества алгоритмов\n",
    "- preprocessing — преобразование признаков\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно даже подходить к решению задач с помощью scikit-learn по следующей схеме. Хотя на самом деле она вам вряд ли понадобится (базовое представление будет и так в вашей голове).\n",
    "![](sklearn_scheme.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте решим несколько задач машинного обучения с помощью scikit-learn и убедимся, что разные виды задач решаются сходим образом. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся стандартным набором данных для классификации цветков ириса на 3 класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "iris['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть выборка состоит из 150 объектов и 4 признаков. Признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная и названия классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['target']\n",
    "iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение двух признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_index = 0\n",
    "y_index = 1\n",
    "\n",
    "# this formatter will label the colorbar with the correct target names\n",
    "formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "\n",
    "plt.scatter(iris.data[:, x_index], iris.data[:, y_index],\n",
    "            c=iris.target, cmap=plt.cm.get_cmap('RdYlBu', 3))\n",
    "plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "plt.clim(-0.5, 2.5)\n",
    "plt.xlabel(iris.feature_names[x_index])\n",
    "plt.ylabel(iris.feature_names[y_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что уже по этим двум признакам визуально можно резделить часть объектов на классы. \n",
    "\n",
    "Построим решающее дерево, классифицирующее объекты (не будем вдаваться в подробности этого метода). Импортируем его:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим и сделаем предсказания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X, y)\n",
    "y_predict = classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем долю правильно классифицированных объектов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predict == y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё ли мы сделали верно?\n",
    "\n",
    "Мы обучались и тестировались на одной и той же выборке. Наш алгоритм хорошо настроился на этой выборке и показал максимально возможный результат. Мы __переобучились__ на нашей обучающей выборке.\n",
    "\n",
    "Однако в реальности нам вряд ли нужен алгоритм, который будет корректно классифицировать те же самые объекты, метки которых мы и так знаем. Поэтому в машинном обучении важно настраивать алгоритмы и оценивать их качество __на разных выборках__.\n",
    "\n",
    "Разделим нашу выборку на 2 равных части: обучающую и контрольную выборки. Для этого воспользуемся функцией из scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова обучим алгоритм и сделаем предсказание уже на тестовой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predict == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь уже не все объекты верно классифицированы. В реальном мире почти нет задач, где можно получить идеальные предсказания с помощью машинного обучения.\n",
    "\n",
    "Заметим, что в последнем эксперименте мы проигнорировали половину выборки для обучения и оценивали качество так же только по половине выборки. Хочется использовать всю выборку для оценки качества. Для этого вместо использования __отложенной выборки__ используется такая техника, как __кросс-валидация__.\n",
    "\n",
    "![](cv.png)\n",
    "\n",
    "Суть заключается в том, что мы делим выборку на несколько частей, для каждой из частей мы обучаем на оставшихся (за исключением текущей) частях алгоритм и оцениваем качество на выбранной части. Посчитанные метрики для каждой из частей усредняем.\n",
    "\n",
    "Для кросс-валидации можно использовать функцию из scikit-learn. Разбиение можно задавать различными способами, но мы будем пользоваться самым простым: случайно на 2 части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(classifier, X, y, scoring='accuracy', cv=2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть наш pipeline был следующим:\n",
    "\n",
    "1. Загрузить данные;\n",
    "2. Обработать их при надобности, визуализировать для понимания;\n",
    "3. Разбить выборку на обучение и контоль (либо воспользовать кросс-валидацией);\n",
    "4. Обучить некоторый алгоритм машинного обучения (будут изучаться на лекциях);\n",
    "5. Оценить качество по некоторой метрике (будут изучаться на лекциях)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача регрессии\n",
    "\n",
    "Загрузим датасет, в котором необходимо предсказывать цену дома."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston['data']\n",
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть выборка состоит из 506 объектов и 13 признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная и названия классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston['target']\n",
    "y[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся линейной регрессией (то есть выразим цену дома как линейную функцию вида $y_i = a_1 x_1 + a_2 x_2 + \\dots + a_{13} x_{13}$, где $x_i$ — признаки дома). Оценивать качество будем с помощью среднеквадратичной ошибки (о функционалах ошибки будет позднее в лекциях). Выборку будем разбивать на 3 части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем воспользоваться другим алгоритмом — случайным лесом (несколько решающих деревьев, ответы которых усредняются)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor()\n",
    "cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=3).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество заметно улучшилось! \n",
    "\n",
    "У большинства алгоритмов в scikit-learn есть гиперпараметры. Их настройка может помочь алгоритмы ещё лучше настроиться на конкретную задачу и показать более высокое качество. \n",
    "\n",
    "Посмотрим на параметры случайного леса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor(<press shift+tab>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, что решая задачу регрессии, мы делали то же самое, что и в классификации за исключением используемых методов и метрик для оценки качества. Scikit-learn позволяет работать с большинством алгоритмов с помощью одних и тех методов (fit, predict, ...). Это позволяет быстро экспериментировать с различными методами при решении конкретных задач."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR', 'description'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "data = fetch_20newsgroups()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пример объекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: guykuo@carson.u.washington.edu (Guy Kuo)\\nSubject: SI Clock Poll - Final Call\\nSummary: Final call for SI clock reports\\nKeywords: SI,acceleration,clock,upgrade\\nArticle-I.D.: shelley.1qvfo9INNc3s\\nOrganization: University of Washington\\nLines: 11\\nNNTP-Posting-Host: carson.u.washington.edu\\n\\nA fair number of brave souls who upgraded their SI clock oscillator have\\nshared their experiences for this poll. Please send a brief message detailing\\nyour experiences with the procedure. Top speed attained, CPU rated speed,\\nadd on cards and adapters, heat sinks, hour of usage per day, floppy disk\\nfunctionality with 800 and 1.4 m floppies are especially requested.\\n\\nI will be summarizing in the next two days, so please add to the network\\nknowledge base if you have done the clock upgrade and haven't answered this\\npoll. Thanks.\\n\\nGuy Kuo <guykuo@u.washington.edu>\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объект представляет собой текст с некоторыми элементами форматирования. Большинство алгоритмов машинного обучения не умеют работать напрямую с текстами. Необходимо представить текст в виде некоторого вектора, чтобы с полученной матрицей объекты-признаки воспользоваться некоторым алгоритмом классификации. Самый простой способ сделать это для текста — посчитать, сколько раз встречается каждое слово в каждом тексте.\n",
    "\n",
    "Предварительно разделим выборку на обучающую и контрольную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В scikit-learn уже реализован класс для подсчёта встречаемости каждого слова в тексте. У него есть различные параметры, связанные с предобработкой текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train)\n",
    "test_vectors = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как слов в языке довольно много, при этом малое количество из них встречается в каждом конкретном тексте, то в полученной матрице, где $i,j$ позиции находится число \"сколько раз в тексте $i$ встречается слово $j$, возникает много нулевых элементов. Такие матрицы называют разреженными и их удобнее хранить в памяти в ином формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors[0].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В процессе кодирования текста мы получили отображение слов в индексы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся логистической регрессией (линейный алгоритм для классификации), обучим его и оценим качество (долю верно предсказанных категорий) на отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_vectors, y_train)\n",
    "y_predict = classifier.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_predict == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять же мы делали все те же самые действия и использовали почти только один scikit-learn.\n",
    "\n",
    "Нам так же могло понадобиться:\n",
    "- закодировать строковый категориальный признак числами (sklearn.preprocessing.LabelEncoding)\n",
    "- воспользовать одной из реализованных метрик для оценки качества (sklearn.metrics)\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
